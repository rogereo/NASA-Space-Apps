{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd93c017",
   "metadata": {},
   "source": [
    "\n",
    "# Enriched Exoplanet Models: KOI + PDCSAP Light Curves\n",
    "\n",
    "**Goal:** Build the *enriched* versions of your 4 baseline models by augmenting the KOI table with features derived from Kepler PDCSAP light curves (via `lightkurve`).  \n",
    "This notebook does **only the enriched side**: it\n",
    "1) Loads a KOI sample (top N rows from your Excel),\n",
    "2) Fetches & preprocesses PDCSAP light curves per KIC,\n",
    "3) Derives robust timeseries features (BLS periodogram, folded stats, basic LC stats),\n",
    "4) Trains 4 models (GradientBoosting, XGBoost, LightGBM, RandomForest),\n",
    "5) Exports a predictions CSV in the **Enriched Model** format you showed.\n",
    "\n",
    "> Tip: Run in Google Colab for easy package setup and internet access (needed to fetch light curves).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb0eeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versions ‚Üí lightkurve 2.5.1 | numpy 2.2.0 | pandas 2.2.3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === If running in Colab, uncomment to install dependencies ===================\n",
    "# !pip -q install lightkurve==2.4.0 astroquery==0.4.9 pywavelets==1.6.0 #                 scikit-learn==1.5.2 xgboost==2.1.1 lightgbm==4.5.0 #                 openpyxl==3.1.5\n",
    "\n",
    "import os, json, re, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Timeseries / astronomy\n",
    "import lightkurve as lk\n",
    "from astropy.timeseries import BoxLeastSquares\n",
    "\n",
    "# Optional wavelet scalogram\n",
    "try:\n",
    "    import pywt  # optional\n",
    "except Exception:\n",
    "    pywt = None\n",
    "\n",
    "# ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# I/O\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Versions ‚Üí\",\n",
    "      \"lightkurve\", lk.__version__,\n",
    "      \"| numpy\", np.__version__,\n",
    "      \"| pandas\", pd.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efd31b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 9564 KOI rows with required fields (TOP_N=None).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kepid</th>\n",
       "      <th>kepoi_name</th>\n",
       "      <th>kepler_name</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_kepmag</th>\n",
       "      <th>koi_disposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10797460</td>\n",
       "      <td>K00752.01</td>\n",
       "      <td>Kepler-227 b</td>\n",
       "      <td>9.488036</td>\n",
       "      <td>170.538750</td>\n",
       "      <td>2.95750</td>\n",
       "      <td>615.8</td>\n",
       "      <td>2.26</td>\n",
       "      <td>793.0</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.927</td>\n",
       "      <td>15.347</td>\n",
       "      <td>Confirmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10797460</td>\n",
       "      <td>K00752.02</td>\n",
       "      <td>Kepler-227 c</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>4.50700</td>\n",
       "      <td>874.8</td>\n",
       "      <td>2.83</td>\n",
       "      <td>443.0</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.927</td>\n",
       "      <td>15.347</td>\n",
       "      <td>Confirmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10811496</td>\n",
       "      <td>K00753.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>1.78220</td>\n",
       "      <td>10829.0</td>\n",
       "      <td>14.60</td>\n",
       "      <td>638.0</td>\n",
       "      <td>5853.0</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.868</td>\n",
       "      <td>15.436</td>\n",
       "      <td>Candidate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10848459</td>\n",
       "      <td>K00754.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>2.40641</td>\n",
       "      <td>8079.2</td>\n",
       "      <td>33.46</td>\n",
       "      <td>1395.0</td>\n",
       "      <td>5805.0</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.791</td>\n",
       "      <td>15.597</td>\n",
       "      <td>False Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10854555</td>\n",
       "      <td>K00755.01</td>\n",
       "      <td>Kepler-664 b</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>1.65450</td>\n",
       "      <td>603.3</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1406.0</td>\n",
       "      <td>6031.0</td>\n",
       "      <td>4.438</td>\n",
       "      <td>1.046</td>\n",
       "      <td>15.509</td>\n",
       "      <td>Confirmed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      kepid kepoi_name   kepler_name  koi_period  koi_time0bk  koi_duration  \\\n",
       "0  10797460  K00752.01  Kepler-227 b    9.488036   170.538750       2.95750   \n",
       "1  10797460  K00752.02  Kepler-227 c   54.418383   162.513840       4.50700   \n",
       "2  10811496  K00753.01           NaN   19.899140   175.850252       1.78220   \n",
       "3  10848459  K00754.01           NaN    1.736952   170.307565       2.40641   \n",
       "4  10854555  K00755.01  Kepler-664 b    2.525592   171.595550       1.65450   \n",
       "\n",
       "   koi_depth  koi_prad  koi_teq  koi_steff  koi_slogg  koi_srad  koi_kepmag  \\\n",
       "0      615.8      2.26    793.0     5455.0      4.467     0.927      15.347   \n",
       "1      874.8      2.83    443.0     5455.0      4.467     0.927      15.347   \n",
       "2    10829.0     14.60    638.0     5853.0      4.544     0.868      15.436   \n",
       "3     8079.2     33.46   1395.0     5805.0      4.564     0.791      15.597   \n",
       "4      603.3      2.75   1406.0     6031.0      4.438     1.046      15.509   \n",
       "\n",
       "  koi_disposition  \n",
       "0       Confirmed  \n",
       "1       Confirmed  \n",
       "2       Candidate  \n",
       "3  False Positive  \n",
       "4       Confirmed  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ================== CONFIG ==================\n",
    "# Path to your KOI Excel file\n",
    "DATA_PATH = \"data/Kepler Object of Interest.xlsx\"   # <-- set to your file\n",
    "TOP_N     = None                      # None = use ALL rows\n",
    "OUT_DIR   = Path(\"./enriched_output\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "target_col = \"koi_disposition\"\n",
    "feature_cols = [\n",
    "    \"koi_period\", \"koi_time0bk\", \"koi_duration\", \"koi_depth\",\n",
    "    \"koi_prad\", \"koi_teq\", \"koi_steff\", \"koi_slogg\", \"koi_srad\", \"koi_kepmag\"\n",
    "]\n",
    "required_id_cols = [\"kepid\", \"kepoi_name\", \"kepler_name\"]\n",
    "required_cols = required_id_cols + feature_cols + [target_col]\n",
    "\n",
    "# Train/test split\n",
    "TEST_SIZE = 0.25\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "\n",
    "def load_koi_sample(xlsx_path: str, top_n=None) -> pd.DataFrame:\n",
    "    df = pd.read_excel(xlsx_path)\n",
    "    # normalize columns\n",
    "    df.columns = [str(c).strip().lower() for c in df.columns]\n",
    "\n",
    "    missing = [c for c in required_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in Excel: {missing}\")\n",
    "\n",
    "    # harmonize label text\n",
    "    df[target_col] = (df[target_col]\n",
    "                      .astype(str)\n",
    "                      .str.strip()\n",
    "                      .str.replace('_', ' ')\n",
    "                      .str.title())  # 'Confirmed','Candidate','False Positive'\n",
    "\n",
    "    # select only needed columns once\n",
    "    base = df[required_cols].copy()\n",
    "\n",
    "    if isinstance(top_n, int) and top_n > 0:\n",
    "        base = base.head(top_n)\n",
    "    return base\n",
    "\n",
    "\n",
    "koi_df = load_koi_sample(DATA_PATH, TOP_N)\n",
    "print(f\"‚úÖ Loaded {len(koi_df)} KOI rows with required fields (TOP_N={TOP_N}).\")\n",
    "koi_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4116152f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 9564 KOI rows with required fields (TOP_N=None).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kepid</th>\n",
       "      <th>kepoi_name</th>\n",
       "      <th>kepler_name</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_kepmag</th>\n",
       "      <th>koi_disposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10797460</td>\n",
       "      <td>K00752.01</td>\n",
       "      <td>Kepler-227 b</td>\n",
       "      <td>9.488036</td>\n",
       "      <td>170.538750</td>\n",
       "      <td>2.95750</td>\n",
       "      <td>615.8</td>\n",
       "      <td>2.26</td>\n",
       "      <td>793.0</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.927</td>\n",
       "      <td>15.347</td>\n",
       "      <td>Confirmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10797460</td>\n",
       "      <td>K00752.02</td>\n",
       "      <td>Kepler-227 c</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>4.50700</td>\n",
       "      <td>874.8</td>\n",
       "      <td>2.83</td>\n",
       "      <td>443.0</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.927</td>\n",
       "      <td>15.347</td>\n",
       "      <td>Confirmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10811496</td>\n",
       "      <td>K00753.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>1.78220</td>\n",
       "      <td>10829.0</td>\n",
       "      <td>14.60</td>\n",
       "      <td>638.0</td>\n",
       "      <td>5853.0</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.868</td>\n",
       "      <td>15.436</td>\n",
       "      <td>Candidate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10848459</td>\n",
       "      <td>K00754.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>2.40641</td>\n",
       "      <td>8079.2</td>\n",
       "      <td>33.46</td>\n",
       "      <td>1395.0</td>\n",
       "      <td>5805.0</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.791</td>\n",
       "      <td>15.597</td>\n",
       "      <td>False Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10854555</td>\n",
       "      <td>K00755.01</td>\n",
       "      <td>Kepler-664 b</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>1.65450</td>\n",
       "      <td>603.3</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1406.0</td>\n",
       "      <td>6031.0</td>\n",
       "      <td>4.438</td>\n",
       "      <td>1.046</td>\n",
       "      <td>15.509</td>\n",
       "      <td>Confirmed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      kepid kepoi_name   kepler_name  koi_period  koi_time0bk  koi_duration  \\\n",
       "0  10797460  K00752.01  Kepler-227 b    9.488036   170.538750       2.95750   \n",
       "1  10797460  K00752.02  Kepler-227 c   54.418383   162.513840       4.50700   \n",
       "2  10811496  K00753.01           NaN   19.899140   175.850252       1.78220   \n",
       "3  10848459  K00754.01           NaN    1.736952   170.307565       2.40641   \n",
       "4  10854555  K00755.01  Kepler-664 b    2.525592   171.595550       1.65450   \n",
       "\n",
       "   koi_depth  koi_prad  koi_teq  koi_steff  koi_slogg  koi_srad  koi_kepmag  \\\n",
       "0      615.8      2.26    793.0     5455.0      4.467     0.927      15.347   \n",
       "1      874.8      2.83    443.0     5455.0      4.467     0.927      15.347   \n",
       "2    10829.0     14.60    638.0     5853.0      4.544     0.868      15.436   \n",
       "3     8079.2     33.46   1395.0     5805.0      4.564     0.791      15.597   \n",
       "4      603.3      2.75   1406.0     6031.0      4.438     1.046      15.509   \n",
       "\n",
       "  koi_disposition  \n",
       "0       Confirmed  \n",
       "1       Confirmed  \n",
       "2       Candidate  \n",
       "3  False Positive  \n",
       "4       Confirmed  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_koi_sample(xlsx_path: str, top_n: int | None = None) -> pd.DataFrame:\n",
    "    df = pd.read_excel(xlsx_path)\n",
    "    # normalize columns\n",
    "    df.columns = [str(c).strip().lower() for c in df.columns]\n",
    "\n",
    "    missing = [c for c in required_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in Excel: {missing}\")\n",
    "\n",
    "    # harmonize label text\n",
    "    df[target_col] = (df[target_col]\n",
    "                      .astype(str)\n",
    "                      .str.strip()\n",
    "                      .str.replace('_', ' ')\n",
    "                      .str.title())  # 'Confirmed','Candidate','False Positive'\n",
    "\n",
    "    # select only the required columns once (avoid join overlap)\n",
    "    base = df[required_cols].copy()\n",
    "\n",
    "    # if a top_n value is provided, limit the sample\n",
    "    if isinstance(top_n, int) and top_n > 0:\n",
    "        base = base.head(top_n)\n",
    "\n",
    "    return base\n",
    "\n",
    "\n",
    "koi_df = load_koi_sample(DATA_PATH, TOP_N)\n",
    "print(f\"‚úÖ Loaded {len(koi_df)} KOI rows with required fields (TOP_N={TOP_N}).\")\n",
    "koi_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5581b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_pdcsap_lightcurve(kic_id: int):\n",
    "    \"\"\"Download & return a stitched, detrended PDCSAP light curve for a given Kepler KIC ID.\"\"\"\n",
    "    try:\n",
    "        search = lk.search_lightcurvefile(f\"KIC {kic_id}\", mission=\"Kepler\")\n",
    "        if search is None or len(search) == 0:\n",
    "            print(f\"‚ö†Ô∏è No light curve files found for KIC {kic_id}.\")\n",
    "            return None\n",
    "\n",
    "        lcf = search.download_all()\n",
    "        if lcf is None:\n",
    "            print(f\"‚ö†Ô∏è Download failed for KIC {kic_id}.\")\n",
    "            return None\n",
    "\n",
    "        # Clean and detrend the PDCSAP flux\n",
    "        lc = lcf.PDCSAP_FLUX.stitch().remove_nans()\n",
    "        if lc is None or len(lc.time) == 0:\n",
    "            print(f\"‚ö†Ô∏è Invalid or empty light curve for KIC {kic_id}.\")\n",
    "            return None\n",
    "\n",
    "        lc = lc.flatten(window_length=401)  # detrend & normalize\n",
    "        return lc\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error fetching LC for KIC {kic_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def compute_bls_periodogram(time, flux, min_period=0.5, max_period=100.0, n_samples=5000, duration_fraction=0.05):\n",
    "    \"\"\"Compute a Box Least Squares (BLS) periodogram and return periods, power, best period, best power.\"\"\"\n",
    "    try:\n",
    "        periods = np.linspace(min_period, max_period, n_samples)\n",
    "        bls = BoxLeastSquares(time, flux)\n",
    "        res = bls.power(periods, duration_fraction)\n",
    "        best_idx = int(np.nanargmax(res.power))\n",
    "        return periods, res.power, float(periods[best_idx]), float(res.power[best_idx])\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è BLS computation failed: {e}\")\n",
    "        return np.array([]), np.array([]), np.nan, np.nan\n",
    "\n",
    "\n",
    "def fold_lightcurve(lc, period, t0):\n",
    "    \"\"\"Phase-fold the light curve by a given period and reference time.\"\"\"\n",
    "    try:\n",
    "        folded = lc.fold(period=period, t0=t0)\n",
    "        return np.array(folded.time.value), np.array(folded.flux.value)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Folding failed: {e}\")\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "\n",
    "def compute_scalogram(time, flux, wavelet=\"morl\", scales=np.arange(1, 128)):\n",
    "    \"\"\"Compute a continuous wavelet transform (scalogram) from flux data.\"\"\"\n",
    "    if pywt is None:\n",
    "        print(\"‚ö†Ô∏è PyWavelets not available ‚Äî skipping scalogram.\")\n",
    "        return None\n",
    "    try:\n",
    "        coef, _ = pywt.cwt(flux, scales, wavelet)\n",
    "        return coef\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Scalogram computation failed: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4321efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_timeseries_features(lc, period=None, t0=None):\n",
    "    \"\"\"Extract statistical and signal features from a Kepler PDCSAP light curve.\"\"\"\n",
    "    # --- Return defaults if light curve is missing ---\n",
    "    if lc is None or len(lc.time.value) == 0:\n",
    "        return dict(\n",
    "            lc_points=0,\n",
    "            lc_flux_mean=np.nan,\n",
    "            lc_flux_std=np.nan,\n",
    "            lc_time_span_days=np.nan,\n",
    "            bls_best_period=np.nan,\n",
    "            bls_best_power=np.nan,\n",
    "            folded_med_depth=np.nan,\n",
    "            folded_odd_even_ratio=np.nan\n",
    "        )\n",
    "\n",
    "    # --- Extract base arrays ---\n",
    "    try:\n",
    "        t = np.array(lc.time.value)\n",
    "        y = np.array(lc.flux.value)\n",
    "    except Exception:\n",
    "        return dict(\n",
    "            lc_points=0,\n",
    "            lc_flux_mean=np.nan,\n",
    "            lc_flux_std=np.nan,\n",
    "            lc_time_span_days=np.nan,\n",
    "            bls_best_period=np.nan,\n",
    "            bls_best_power=np.nan,\n",
    "            folded_med_depth=np.nan,\n",
    "            folded_odd_even_ratio=np.nan\n",
    "        )\n",
    "\n",
    "    # --- Basic statistics ---\n",
    "    feats = dict(\n",
    "        lc_points=int(len(y)),\n",
    "        lc_flux_mean=float(np.nanmean(y)),\n",
    "        lc_flux_std=float(np.nanstd(y)),\n",
    "        lc_time_span_days=float(t.max() - t.min()) if len(t) > 1 else np.nan,\n",
    "        bls_best_period=np.nan,\n",
    "        bls_best_power=np.nan,\n",
    "        folded_med_depth=np.nan,\n",
    "        folded_odd_even_ratio=np.nan\n",
    "    )\n",
    "\n",
    "    # --- Compute BLS periodogram ---\n",
    "    try:\n",
    "        periods, power, best_p, best_pow = compute_bls_periodogram(t, y)\n",
    "        if np.isfinite(best_p) and np.isfinite(best_pow):\n",
    "            feats[\"bls_best_period\"] = best_p\n",
    "            feats[\"bls_best_power\"] = best_pow\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è BLS feature extraction failed: {e}\")\n",
    "\n",
    "    # --- Compute folded features if KOI period and t0 are provided ---\n",
    "    if period is not None and t0 is not None and np.isfinite(period) and np.isfinite(t0):\n",
    "        try:\n",
    "            folded = lc.fold(period=period, t0=t0)\n",
    "            ph = np.array(folded.time.value)\n",
    "            yf = np.array(folded.flux.value)\n",
    "\n",
    "            if len(ph) > 0 and len(yf) > 0:\n",
    "                # median flux depth near transit (phase ~0)\n",
    "                mask_in = np.abs(ph) < 0.1 * period\n",
    "                feats[\"folded_med_depth\"] = float(\n",
    "                    np.nanmedian(yf[mask_in]) - np.nanmedian(yf[~mask_in])\n",
    "                )\n",
    "\n",
    "                # odd-even depth ratio to detect eclipsing binaries\n",
    "                d1 = np.nanmedian(yf[(ph >= -0.25 * period) & (ph < 0.0 * period)])\n",
    "                d2 = np.nanmedian(yf[(ph >= 0.0 * period) & (ph < 0.25 * period)])\n",
    "                feats[\"folded_odd_even_ratio\"] = (\n",
    "                    float(d1 / d2) if np.isfinite(d1) and np.isfinite(d2) and d2 != 0 else np.nan\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Folded feature computation failed: {e}\")\n",
    "\n",
    "    return feats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3960f869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî≠ Processing KIC 10797460 | P ‚âà 9.488 d | t0 ‚âà 170.539 BKJD\n",
      "‚ö†Ô∏è PyWavelets not available ‚Äî skipping scalogram.\n",
      "\n",
      "üî≠ Processing KIC 10797460 | P ‚âà 54.418 d | t0 ‚âà 162.514 BKJD\n",
      "‚ö†Ô∏è PyWavelets not available ‚Äî skipping scalogram.\n",
      "\n",
      "üî≠ Processing KIC 10811496 | P ‚âà 19.899 d | t0 ‚âà 175.850 BKJD\n",
      "‚ö†Ô∏è PyWavelets not available ‚Äî skipping scalogram.\n",
      "\n",
      "üî≠ Processing KIC 10848459 | P ‚âà 1.737 d | t0 ‚âà 170.308 BKJD\n",
      "‚ö†Ô∏è PyWavelets not available ‚Äî skipping scalogram.\n",
      "\n",
      "üî≠ Processing KIC 10854555 | P ‚âà 2.526 d | t0 ‚âà 171.596 BKJD\n",
      "‚ö†Ô∏è PyWavelets not available ‚Äî skipping scalogram.\n",
      "\n",
      "üî≠ Processing KIC 10872983 | P ‚âà 11.094 d | t0 ‚âà 171.201 BKJD\n",
      "‚ö†Ô∏è PyWavelets not available ‚Äî skipping scalogram.\n",
      "\n",
      "üî≠ Processing KIC 10872983 | P ‚âà 4.134 d | t0 ‚âà 172.979 BKJD\n",
      "‚ö†Ô∏è PyWavelets not available ‚Äî skipping scalogram.\n",
      "\n",
      "üî≠ Processing KIC 10872983 | P ‚âà 2.567 d | t0 ‚âà 179.554 BKJD\n",
      "‚ö†Ô∏è PyWavelets not available ‚Äî skipping scalogram.\n",
      "\n",
      "üî≠ Processing KIC 6721123 | P ‚âà 7.362 d | t0 ‚âà 132.251 BKJD\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 107\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m enriched\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# --- Run enrichment ---\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m enriched_df \u001b[38;5;241m=\u001b[39m \u001b[43menrich_koi_with_lc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkoi_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEnriched KOI (preview):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    109\u001b[0m display(enriched_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[1;32mIn[8], line 23\u001b[0m, in \u001b[0;36menrich_koi_with_lc\u001b[1;34m(koi_df, save_artifacts)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müî≠ Processing KIC \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkic\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | P ‚âà \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mperiod\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m d | t0 ‚âà \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt0\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m BKJD\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# --- Fetch PDCSAP light curve ---\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m lc \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_pdcsap_lightcurve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ö†Ô∏è Skipping KIC \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkic\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (no valid light curve).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 20\u001b[0m, in \u001b[0;36mfetch_pdcsap_lightcurve\u001b[1;34m(kic_id)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ö†Ô∏è Invalid or empty light curve for KIC \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkic_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     lc \u001b[38;5;241m=\u001b[39m \u001b[43mlc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m401\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# detrend & normalize\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lc\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\roger\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\lightkurve\\lightcurve.py:929\u001b[0m, in \u001b[0;36mLightCurve.flatten\u001b[1;34m(self, window_length, polyorder, return_trend, break_tolerance, niters, sigma, mask, **kwargs)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l, h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(low, high):\n\u001b[0;32m    925\u001b[0m     \u001b[38;5;66;03m# Reduce `window_length` and `polyorder` for short segments;\u001b[39;00m\n\u001b[0;32m    926\u001b[0m     \u001b[38;5;66;03m# this prevents `savgol_filter` from raising an exception\u001b[39;00m\n\u001b[0;32m    927\u001b[0m     \u001b[38;5;66;03m# If the segment is too short, just take the median\u001b[39;00m\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many([window_length \u001b[38;5;241m>\u001b[39m (h \u001b[38;5;241m-\u001b[39m l), (h \u001b[38;5;241m-\u001b[39m l) \u001b[38;5;241m<\u001b[39m break_tolerance]):\n\u001b[1;32m--> 929\u001b[0m         trend_signal[l:h] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmedian(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflux\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m[l:h])\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    931\u001b[0m         \u001b[38;5;66;03m# Scipy outputs a warning here that is not useful, will be fixed in version 1.2\u001b[39;00m\n\u001b[0;32m    932\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n",
      "File \u001b[1;32mc:\\Users\\roger\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\astropy\\units\\quantity.py:1282\u001b[0m, in \u001b[0;36mQuantity.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_view(\n\u001b[0;32m   1278\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39mndarray)[key], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit[key], propagate_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m     )\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1282\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[0;32m   1284\u001b[0m     \u001b[38;5;66;03m# We want zero-dimensional Quantity objects to behave like scalars,\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m     \u001b[38;5;66;03m# so they should raise a TypeError rather than an IndexError.\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misscalar:\n",
      "File \u001b[1;32mc:\\Users\\roger\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\astropy\\utils\\shapes.py:72\u001b[0m, in \u001b[0;36mNDArrayShapeMethods.__getitem__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__getitem__\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\roger\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\astropy\\utils\\masked\\core.py:344\u001b[0m, in \u001b[0;36mMasked._apply\u001b[1;34m(self, method, *args, **kwargs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     mask \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 344\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munmasked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    345\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask, method)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    347\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_unmasked(data, mask, copy\u001b[38;5;241m=\u001b[39mCOPY_IF_NEEDED)\n",
      "File \u001b[1;32mc:\\Users\\roger\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\astropy\\units\\quantity.py:1282\u001b[0m, in \u001b[0;36mQuantity.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_view(\n\u001b[0;32m   1278\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39mndarray)[key], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit[key], propagate_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m     )\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1282\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[0;32m   1284\u001b[0m     \u001b[38;5;66;03m# We want zero-dimensional Quantity objects to behave like scalars,\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m     \u001b[38;5;66;03m# so they should raise a TypeError rather than an IndexError.\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misscalar:\n",
      "File \u001b[1;32mc:\\Users\\roger\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\astropy\\units\\quantity.py:566\u001b[0m, in \u001b[0;36mQuantity.__array_finalize__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    562\u001b[0m         \u001b[38;5;66;03m# here we had non-Quantity input that had a \"unit\" attribute\u001b[39;00m\n\u001b[0;32m    563\u001b[0m         \u001b[38;5;66;03m# with a unit different from the desired one.  So, convert.\u001b[39;00m\n\u001b[0;32m    564\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m value\u001b[38;5;241m.\u001b[39mto(unit)\n\u001b[1;32m--> 566\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array_finalize__\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj):\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;66;03m# Check whether super().__array_finalize should be called\u001b[39;00m\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;66;03m# (sadly, ndarray.__array_finalize__ is None; we cannot be sure\u001b[39;00m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;66;03m# what is above us).\u001b[39;00m\n\u001b[0;32m    570\u001b[0m     super_array_finalize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m__array_finalize__\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m super_array_finalize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def enrich_koi_with_lc(koi_df: pd.DataFrame, save_artifacts: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each KOI entry:\n",
    "      - Fetch PDCSAP light curve (via Lightkurve)\n",
    "      - Compute derived timeseries features (BLS, folded stats, LC stats)\n",
    "      - Optionally save diagnostic plots\n",
    "      - Return an enriched DataFrame combining original columns + features + artifact paths\n",
    "    \"\"\"\n",
    "    records = []\n",
    "\n",
    "    for idx, row in koi_df.iterrows():\n",
    "        try:\n",
    "            kic = int(row.get(\"kepid\", np.nan))\n",
    "            period = float(row.get(\"koi_period\", np.nan))\n",
    "            t0 = float(row.get(\"koi_time0bk\", np.nan))\n",
    "        except Exception:\n",
    "            print(f\"‚ö†Ô∏è Row {idx}: invalid numeric values, skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nüî≠ Processing KIC {kic} | P ‚âà {period:.3f} d | t0 ‚âà {t0:.3f} BKJD\")\n",
    "\n",
    "        # --- Fetch PDCSAP light curve ---\n",
    "        lc = fetch_pdcsap_lightcurve(kic)\n",
    "        if lc is None:\n",
    "            print(f\"‚ö†Ô∏è Skipping KIC {kic} (no valid light curve).\")\n",
    "            feats = derive_timeseries_features(None)\n",
    "            art = {\"plots\": {}, \"status\": \"no_lightcurve\"}\n",
    "            rec = row.to_dict(); rec.update(feats); rec[\"artifacts\"] = json.dumps(art)\n",
    "            records.append(rec)\n",
    "            continue\n",
    "\n",
    "        # --- Derive light curve features ---\n",
    "        feats = derive_timeseries_features(lc, period=period, t0=t0)\n",
    "        art = {\"plots\": {}, \"status\": \"ok\"}\n",
    "\n",
    "        # --- Save plots & diagnostics ---\n",
    "        if save_artifacts:\n",
    "            try:\n",
    "                # Raw light curve\n",
    "                fig = plt.figure()\n",
    "                plt.plot(lc.time.value, lc.flux.value, linewidth=0.7)\n",
    "                plt.xlabel(\"Time [BKJD]\"); plt.ylabel(\"Normalized Flux\")\n",
    "                plt.title(f\"KIC {kic} ‚Äî PDCSAP (detrended)\")\n",
    "                pth = str((OUT_DIR / f\"kic_{kic}_raw_lc.png\").resolve())\n",
    "                plt.tight_layout(); plt.savefig(pth, dpi=150); plt.close(fig)\n",
    "                art[\"plots\"][\"raw_lc\"] = pth\n",
    "\n",
    "                # Phase-folded view\n",
    "                ph, f = fold_lightcurve(lc, period, t0)\n",
    "                if len(ph) > 0:\n",
    "                    fig2 = plt.figure()\n",
    "                    plt.scatter(ph, f, s=2, alpha=0.3)\n",
    "                    plt.xlabel(\"Phase [days]\"); plt.ylabel(\"Flux\")\n",
    "                    plt.title(f\"KIC {kic} ‚Äî Phase-folded ({period:.3f} d)\")\n",
    "                    pth2 = str((OUT_DIR / f\"kic_{kic}_folded.png\").resolve())\n",
    "                    plt.tight_layout(); plt.savefig(pth2, dpi=150); plt.close(fig2)\n",
    "                    art[\"plots\"][\"folded\"] = pth2\n",
    "\n",
    "                # BLS periodogram\n",
    "                try:\n",
    "                    periods, power, best_p, best_pow = compute_bls_periodogram(\n",
    "                        lc.time.value, lc.flux.value\n",
    "                    )\n",
    "                    if len(periods) > 0:\n",
    "                        feats[\"bls_best_period\"] = float(best_p)\n",
    "                        feats[\"bls_best_power\"] = float(best_pow)\n",
    "                        fig3 = plt.figure()\n",
    "                        plt.plot(periods, power, linewidth=0.7)\n",
    "                        plt.xlabel(\"Trial Period [days]\"); plt.ylabel(\"BLS Power\")\n",
    "                        plt.title(f\"KIC {kic} ‚Äî BLS (best ‚âà {best_p:.3f} d)\")\n",
    "                        pth3 = str((OUT_DIR / f\"kic_{kic}_bls.png\").resolve())\n",
    "                        plt.tight_layout(); plt.savefig(pth3, dpi=150); plt.close(fig3)\n",
    "                        art[\"plots\"][\"bls\"] = pth3\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è BLS plot failed for KIC {kic}: {e}\")\n",
    "\n",
    "                # Optional: Wavelet scalogram\n",
    "                try:\n",
    "                    coef = compute_scalogram(lc.time.value, lc.flux.value)\n",
    "                    if coef is not None:\n",
    "                        fig4 = plt.figure()\n",
    "                        plt.imshow(coef, aspect=\"auto\", origin=\"lower\")\n",
    "                        plt.xlabel(\"Time Index\"); plt.ylabel(\"Scale\")\n",
    "                        plt.title(f\"KIC {kic} ‚Äî Wavelet Scalogram\")\n",
    "                        pth4 = str((OUT_DIR / f\"kic_{kic}_scalogram.png\").resolve())\n",
    "                        plt.tight_layout(); plt.savefig(pth4, dpi=150); plt.close(fig4)\n",
    "                        art[\"plots\"][\"scalogram\"] = pth4\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Scalogram skipped for KIC {kic}: {e}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Artifact saving failed for KIC {kic}: {e}\")\n",
    "\n",
    "        # --- Merge results ---\n",
    "        rec = row.to_dict()\n",
    "        rec.update(feats)\n",
    "        rec[\"artifacts\"] = json.dumps(art)\n",
    "        records.append(rec)\n",
    "\n",
    "    # --- Combine enriched records ---\n",
    "    enriched = pd.DataFrame(records)\n",
    "    print(f\"\\n‚úÖ Enrichment complete: {len(enriched)} KOIs processed.\")\n",
    "    return enriched\n",
    "\n",
    "\n",
    "# --- Run enrichment ---\n",
    "enriched_df = enrich_koi_with_lc(koi_df)\n",
    "print(\"\\nEnriched KOI (preview):\")\n",
    "display(enriched_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9781e0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select model features: original KOI numeric + derived LC features\n",
    "derived_cols = [\"lc_points\",\"lc_flux_mean\",\"lc_flux_std\",\"lc_time_span_days\",\n",
    "                \"bls_best_period\",\"bls_best_power\",\"folded_med_depth\",\"folded_odd_even_ratio\"]\n",
    "\n",
    "model_features = feature_cols + derived_cols\n",
    "X = enriched_df[model_features].copy()\n",
    "y = enriched_df[target_col].copy()\n",
    "\n",
    "# Numeric preprocessing (impute + scale)\n",
    "numeric_processor = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "preproc = ColumnTransformer(\n",
    "    transformers=[(\"num\", numeric_processor, model_features)],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(X_train)}  Test size: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ffffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    \"Gradient Boosting EM\": GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    \"XGBoost EM\":          XGBClassifier(\n",
    "        n_estimators=300, max_depth=5, learning_rate=0.05, subsample=0.9,\n",
    "        colsample_bytree=0.9, objective=\"multi:softprob\", eval_metric=\"mlogloss\",\n",
    "        random_state=RANDOM_STATE, n_jobs=-1\n",
    "    ),\n",
    "    \"LightGBM EM\":         LGBMClassifier(\n",
    "        n_estimators=400, learning_rate=0.05, subsample=0.9,\n",
    "        colsample_bytree=0.9, objective=\"multiclass\", random_state=RANDOM_STATE\n",
    "    ),\n",
    "    \"RandomForest EM\":     RandomForestClassifier(\n",
    "        n_estimators=600, max_depth=None, min_samples_split=2,\n",
    "        random_state=RANDOM_STATE, n_jobs=-1\n",
    "    ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdc1ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit models\n",
    "fitted = {}\n",
    "for name, clf in models.items():\n",
    "    pipe = Pipeline(steps=[(\"pre\", preproc), (\"clf\", clf)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    fitted[name] = pipe\n",
    "    print(f\"‚úÖ Trained: {name}\")\n",
    "\n",
    "# Predictions table in your *Enriched Model* format\n",
    "pred_df = pd.DataFrame({\n",
    "    \"Star System\": enriched_df[\"kepid\"].iloc[X_test.index].values,\n",
    "    \"Planet\":      enriched_df[\"kepler_name\"].iloc[X_test.index].values,\n",
    "})\n",
    "\n",
    "for name, pipe in fitted.items():\n",
    "    pred = pipe.predict(X_test)\n",
    "    pred_df[name] = pred\n",
    "\n",
    "pred_df[\"Actual EM\"] = y_test.values\n",
    "\n",
    "# Consistent ordering of columns\n",
    "col_order = [\"Gradient Boosting EM\",\"XGBoost EM\",\"LightGBM EM\",\"RandomForest EM\",\"Actual EM\"]\n",
    "pred_df = pred_df[[\"Star System\",\"Planet\"] + col_order]\n",
    "\n",
    "# Save CSV\n",
    "csv_path = OUT_DIR / \"koi_enriched_predictions.csv\"\n",
    "pred_df.to_csv(csv_path, index=False)\n",
    "print(\"Saved predictions ‚Üí\", csv_path.resolve())\n",
    "\n",
    "pred_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9708fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Quick text reports per model (on test set)\n",
    "for name, pipe in fitted.items():\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    print(\"\\n=== Report:\", name, \"===\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54757258",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "enriched_csv = OUT_DIR / f\"koi_enriched_{len(enriched_df)}rows.csv\"\n",
    "enriched_df.to_csv(enriched_csv, index=False)\n",
    "print(\"Saved enriched dataframe ‚Üí\", enriched_csv.resolve())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
